<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Face Recognition App</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <style>
    body {
      background-color: #f0f0f0;
    }

    .container {
      max-width: 800px;
      margin: 40px auto;
      padding: 20px;
      background-color: #fff;
      border: 1px solid #ddd;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }

    #video {
      width: 640px;
      height: 480px;
      border: 1px solid black;
      display: block;
      margin: 20px auto;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
</head>
<body>

<div class="container">
  <h1 class="text-center">Face Recognition App</h1>
  <p class="text-center">This app detects faces and displays names using a JSON-based list of known people.</p>
  <button class="btn btn-primary mx-auto d-block" id="start-btn">Start Recognition</button>
  <video id="video" autoplay muted></video>
  <canvas id="canvas"></canvas>
</div>

<script>
  const video = document.getElementById('video');
  const canvas = document.getElementById('canvas');
  const startBtn = document.getElementById('start-btn');

  // 👤 JSON of known people with image URLs and names
  const knownFacesJSON = [
   const knownFaces = [
  { name: "Alice", url: "https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/examples/images/bbt1.jpg" },
  { name: "Bob", url: "https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/examples/images/bbt2.jpg" }
];


  // Load models and start recognition
  startBtn.addEventListener('click', async () => {
    await Promise.all([
      faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
      faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
      faceapi.nets.faceRecognitionNet.loadFromUri('/models')
    ]);

    await startVideo();
    await recognizeFaces();
  });

  // 📷 Start webcam
  async function startVideo() {
    const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
    video.srcObject = stream;
  }

  // 🧠 Load labeled face descriptors
  async function loadLabeledImages() {
    return Promise.all(
      knownFacesJSON.map(async person => {
        const img = await faceapi.fetchImage(person.url);
        const detection = await faceapi
          .detectSingleFace(img)
          .withFaceLandmarks()
          .withFaceDescriptor();
        if (!detection) throw new Error(`No face detected for ${person.name}`);
        return new faceapi.LabeledFaceDescriptors(person.name, [detection.descriptor]);
      })
    );
  }

  // 🔍 Start recognition loop
  async function recognizeFaces() {
    const labeledDescriptors = await loadLabeledImages();
    const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

    canvas.width = video.width;
    canvas.height = video.height;

    video.addEventListener('play', () => {
      const interval = setInterval(async () => {
        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks()
          .withFaceDescriptors();

        const resized = faceapi.resizeResults(detections, {
          width: video.width,
          height: video.height
        });

        const ctx = canvas.getContext('2d');
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        resized.forEach(detection => {
          const match = faceMatcher.findBestMatch(detection.descriptor);
          const box = detection.detection.box;
          const drawBox = new faceapi.draw.DrawBox(box, { label: match.toString() });
          drawBox.draw(canvas);
        });
      }, 300);
    });
  }
</script>

</body>
</html>
